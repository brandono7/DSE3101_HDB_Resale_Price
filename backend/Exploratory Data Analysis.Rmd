---
title: "Exploratory Data Analysis"
author: "Jessica Widyawati"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Load packages and datasets
```{r warning = FALSE}
# load the required packages
library(tidyverse)
library(plotly)
library(lubridate)
library(caret)
library(httr) 
library(jsonlite)
library(car)
library(gridExtra)

# load our cleaned dataset
hdb_resale = read.csv("processed_data/hdb_resale_prices.csv") %>% select(-1)

#load our cleaned dataset with only continuous variables
hdb_resale_cont <- read.csv("processed_data/hdb_resale_continuous.csv") %>% select(-1)
```

## Correlation matrix
```{r pressure, echo=FALSE}
#build a correlation heatmap to test for correlation between continuous variables
correlation_matrix <- cor(hdb_resale_cont)

# Create a plotly heatmap with labels
plot_ly(z = correlation_matrix, type = "heatmap",
        x = colnames(correlation_matrix), y = colnames(correlation_matrix),
        text = paste("Variable 1: ", colnames(correlation_matrix), "<br>",
                     "Variable 2: ", rownames(correlation_matrix), "<br>",
                     "Correlation: ", round(correlation_matrix, 2), "<br>",
                     sep = "")) %>%
  layout(title = "Correlation Heatmap of Continuous Variables",
         xaxis = list(title = ""),
         yaxis = list(title = ""))

#find the highest correlated variables:

# Flatten the upper triangle of the correlation matrix (excluding the diagonal)
correlation_values <- as.vector(correlation_matrix[upper.tri(correlation_matrix)])

# Find the indices of the highest correlation values
top_correlation_indices <- order(correlation_values, decreasing = TRUE)[1:10]  # Adjust the number as needed

# Extract corresponding variable pairs and their correlation values
top_variable_pairs <- expand.grid(Variables_1 = colnames(correlation_matrix),
                                  Variables_2 = rownames(correlation_matrix))[top_correlation_indices, ]
top_correlation_values <- correlation_values[top_correlation_indices]

# Combine variable pairs and correlation values
top_correlation_results <- data.frame(top_variable_pairs, Correlation_Value = top_correlation_values)

# Print the top correlated variable pairs
print(top_correlation_results)

model <- lm(resale_price ~ ., data = hdb_resale_cont)
vif(model)
```

## Plot the histogram to check the skewness of price
```{r}
# Plot the HDB resale prices (density plot) to see the skewness of prices n whether we need to transform the data
# Plot histogram of resale prices
ggplot(hdb_resale, aes(x = resale_price)) +
  geom_histogram(binwidth = 10000, fill = "skyblue", color = "black") +
  labs(title = "Histogram of HDB Resale Prices",
       x = "Resale Price (SGD)",
       y = "Frequency") +
  theme_minimal()

# we do log transformation because this tends to compress higher values more than lower values, hence reducing the right skewness.

# Log transformation of resale prices
hdb_resale$log_resale_price <- log(hdb_resale$resale_price)

# Plot histogram of log-transformed resale prices
ggplot(hdb_resale, aes(x = log_resale_price)) +
  geom_histogram(binwidth = 0.2, fill = "skyblue", color = "black") +
  labs(title = "Histogram of Log-Transformed HDB Resale Prices",
       x = "Log(Resale Price)",
       y = "Frequency") +
  theme_minimal()
```

# Distributions of the regressors
```{r}
# Select all numeric variables except log_resale_price
numeric_vars <- hdb_resale_cont %>%
  select(-resale_price)

# Function to create histograms for each variable
plot_histograms <- function(data) {
  plots <- lapply(names(data), function(var) {
    ggplot(data, aes_string(x = var)) +
      geom_histogram(binwidth = 0.2, fill = "skyblue", color = "black") +
      labs(title = paste("Histogram of", var),
           x = var,
           y = "Frequency") +
      theme_minimal()
  })
  return(plots)
}

# Create histograms for all numeric variables
histogram_plots <- plot_histograms(numeric_vars)

histogram_plots
```

### check for outliers
```{r}
# using Tukey's definition of outliers:

find_outliers <- function(data, threshold = 1.5) {
  outliers <- list()
  for (col in colnames(data)) {
    # Calculate the lower and upper quartiles
    q1 <- quantile(data[[col]], 0.25)
    q3 <- quantile(data[[col]], 0.75)
    
    # Calculate the IQR
    iqr <- q3 - q1
    
    # Define the lower and upper bounds for outliers
    lower_bound <- q1 - threshold * iqr
    upper_bound <- q3 + threshold * iqr
    
    # Find outliers in the column
    outliers[[col]] <- data[[col]][data[[col]] < lower_bound | data[[col]] > upper_bound]
  }
  return(outliers)
}

#check for outliers
outliers <- find_outliers(hdb_resale_cont)

boxplot(hdb_resale$resale_price)

# Testing for influential points
C = cooks.distance(lm(resale_price~., data = hdb_resale_cont)) 
which(C>1)
# No influential points found.
```

## Plot a barplot of median prices in each town
```{r}
# plot median HDB resale prices by town, facet wrap by other categories

#read in non transformed data
hdb_ori <- read.csv("processed_data/hdb_merged_no_transform.csv") %>% select(-1)

# Calculate median resale price by town
median_prices <- aggregate(resale_price ~ town, hdb_ori, median)

# Reorder town based on median resale prices (from highest to lowest)
hdb_ori$town <- factor(hdb_ori$town, levels = median_prices[order(median_prices$resale_price, decreasing = TRUE), "town"])

# Create another column called median_prices
# Calculate median resale price for each town
median_prices <- hdb_ori %>%
  group_by(town) %>%
  summarise(median_price = median(resale_price, na.rm = TRUE))

median_prices$town <- reorder(median_prices$town, -median_prices$median_price)

# Plot barplot of median prices vs. town and facet wrap by flat_type
ggplot(median_prices, aes(x = town, y = median_price)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  labs(title = "Median HDB Resale Prices by Town",
       x = "Town",
       y = "Median Resale Price (SGD)") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1, size = 7))
```